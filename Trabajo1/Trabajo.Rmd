---
header-includes:
- \usepackage{longtable}
- \usepackage[utf8]{inputenc}
- \usepackage[spanish]{babel}\decimalpoint
- \setlength{\parindent}{0cm}
- \usepackage{amsmath}
- \usepackage{array}
- \usepackage{float}
- \usepackage{multirow}
output:
  pdf_document:
    number_sections: yes
  word_document: default
fontsize: 12pt
papersize: letter
geometry: margin = 1in
language: es
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, fig.align = "center", fig.pos = "H")
library(kableExtra)
library(knitr)
library(leaps)
source("Functions.R")
library(tidyverse)
```

```{=tex}
\input{titlepage}
\thispagestyle{empty}
\tableofcontents
\newpage
\thispagestyle{empty}
\listoffigures
\listoftables
\newpage
```
```{=tex}
\pagestyle{myheadings}
\setcounter{page}{3}
```
\section{Pregunta 1}

Teniendo en cuenta la base de datos brindada, en la cual hay 5 variables
regresoras dadas por:

$Y$ : Riesgo de infección

$X_1$: Duración de la estadía

$X_1$: Rutina de vultivos

$X_1$: Número de camas

$X_1$: Censo promdeio diario

$X_1$: Número de enfermeras

$$Y_i = \beta_o + \beta_1 X_{i1} + \beta_2 X_{i2} + \beta_3 X_{i3} + \beta_4 X_{i4} + \beta_5X_{i5}+ \varepsilon_i, \ \varepsilon_i \stackrel{\text{iid}}{\sim} N(0, \sigma^2); \ 1 \leqslant i \leqslant 60$$


```{r}
datos <- read.table("Equipo06.txt", header = T)
modelo <- lm(Y ~ ., data = datos)
betas <- round(coef(modelo), 4)
betas1 <- as.data.frame(betas)
```

\subsection{Modelo de regresión}

Al cargar y ajustar el modelo lineal, se obtienen los siguientes coeficientes estimados del MRLM:

```{r}
rownames(betas1) <- c("$\\beta_0$", "$\\beta_1$", "$\\beta_2$", "$\\beta_3$", "$\\beta_4$", "$\\beta_5$")
betas1 %>% 
  kable(col.names = c("Valor del parámetro"), caption = "Tabla de valores coeficientes del modelo", escape = F, booktab = T, align = "c", row.names = T) %>% 
  kable_styling(latex_options = c("HOLD_position"))
```

Por lo tanto, el modelo de regresión ajustado es:
$$\hat{Y}_i = `r betas[1]` + `r betas[2]` X_{1i} `r betas[3]` X_{2i} + `r betas[4]` X_{3i} +`r betas[5]` X_{4i} + 0.0008X_{5i} +\varepsilon_i, \ \varepsilon_i \stackrel{\text{iid}}{\sim} N(0, \sigma^2); \ 1 \leqslant i \leqslant 60$$

\subsection{Significancia de la regresión}

Para realizar la prueba de significancia del modelo de regresión planteamos el siguiente juego de hipótesis
 $$
\begin{cases}
  \begin{aligned}
    H_0&: \beta_1=\beta_2=\beta_3=\beta_4=\beta_5=0 \\
    H_1&: \text{algún }\beta_j\neq \text{0,   j=1, 2, 3, 4, 5}
  \end{aligned}
\end{cases}
$$ Cuyo estadístico de prueba es:

```{=tex}
\begin{equation}
F_0 = \frac{MSR}{MSE} \stackrel{H_0}{\sim} f_{5, `r nrow(datos)-6`}\\
\end{equation}
```
Ahora, se presenta la tabla Anova:

```{r}
tabla.anova <- myAnova(modelo)
rownames(tabla.anova) <- c("Regresión", "Error")
tabla.anova %>% 
  kable(col.names = c("Sumas de cuadrados", "Grados de libertad.", "Cuadrado medio", "$F_0$", "valor P"),caption = "Tabla  ANOVA para el modelo", escape=F, booktab=T, align = "c", row.names = T) %>% 
  kable_styling(latex_options = c("HOLD_position"))
```

De la tabla Anova, se compara el valor P que es de 7.80158e-12, con un nivel de significancia $\alpha = 0.05$ permitiendo
que se rechaze la hipótesis nula en la que $\beta_1=\beta_2=\beta_3=\beta_4=\beta_5=0$,
probando que existe una relacion en la regresión.

\subsection{Significancia  de los parámetros}

En la siguiente tabla se aprecia la información de los parámetros que permite
determinar la significancia de cada uno de estos.

```{r}
tabla.coeficientes <- summary(modelo)$coefficients
rownames(tabla.coeficientes) <- paste("$\\beta_", 0:5, "$", sep = "")
tabla.coeficientes %>% 
  kable(col.names = c("$Valor estimado$", "$SE(\\hat{\\beta_j})$", "$T_{0j}$", "P-valor"),caption = "Resumen de los coeficientes", escape=F, booktab=T, align = "c", row.names = T, digits = 4) %>% 
  kable_styling(latex_options = c("HOLD_position"))
```

Para analizar la significancia de los coeficientes en el modelo lineal emplearemos un nivel de significancia = 0.05 para comparar con el valor P arrojado por el resumen de los coeficientes.

Los P-valores presentes en la tabla permiten concluir que con un nivel
de significancia $\alpha = 0.05$, los parámetros $\beta_3$ y $\beta_5$
son significativos, pues sus P-valores son menores a $\alpha$.

\subsection{Interpretación de los parámetros}

\textbf{$\hat{\beta_3}$:}

\textbf{$\hat{\beta_5}$:}

\subsection{Coeficiente de determinación múltiple $R^2$}
Para hallar el coeficiente de determinación múltiple $R^2$ empleamos el SSR y SSE dados por la tabla ANOVA

$R^2 = \frac{SSR}{SST} = \frac{SSR}{SSR + SSE} = \frac{91.8115}{137.5618} = 0.667420$

Este coeficiente de determinación nos dice que aproximadamente el $66.74\%$ de la variabilidad observada en la respuesta es explicada por el modelo de regresión propuesto en el presente informe.

```{=tex}
\section{Pregunta 2}
\subsection{Planteamiento pruebas de hipótesis}
```
Las variables con el valor P más alto en el modelo fueron
$X_1, X_2, X_5$

para probar la significancia simultánea de estos tres coeficientes de la regresión planteamos las hipótesis:

$$
\begin{cases}
\begin{aligned}
\text{H}_0&: \beta_1 =\beta_2 = \beta_5 = 0\\
\text{H}_1&: \text{algún }\beta_j\neq \text{0,   j=1, 2, 5}
\end{aligned}
\end{cases}
$$

```{r}
todas.regresiones <- myAllRegTable(modelo)
todas.regresiones <- todas.regresiones[c(31, 7), c(4, 6)]
row.names(todas.regresiones) <- c("Modelo  completo", "Modelo reducido")
todas.regresiones %>% 
    kable(col.names = c("$SSE$", "Covariables en el modelo"), caption = "tabla de todas las regresiones resumida", escape=F, booktab=T, align = "c", row.names = T, digits = 4) %>% 
  kable_styling(latex_options = c("HOLD_position"))
```

El modelo completo es el visto en el inicio de la pregunta 1.

El modelo reducido es de la forma:

$$Y_i = \beta_0 + \beta_3 X_{3i} + \beta_4 X_{4i} + \varepsilon; \ \varepsilon_i \stackrel{\text{iid}}{\sim} N(0, \sigma^2); \ 1 \leqslant i \leqslant 60$$

\subsection{Estadístico de prueba y conclusión}

Se calcula el estadistico de la prueba de la forma:

```{=tex}
\begin{equation}
\begin{split}
F_0 &= \frac{SSR(\beta_1, \beta_2, \beta_5 | \beta_0, \beta_3, \beta_4)/3}{SSE(\beta_0, \beta_1, \beta_3, \beta_4, \beta_5)/54} \\
&= \frac{(SSE(\beta_0, \beta_3, \beta_4) - SSE(\beta_0, \beta_1, \beta_3, \beta_4, \beta_5))/3}{SSE(\beta_0, \beta_1, \beta_3, \beta_4, \beta_5)/54} \\
&= \frac{11.618/3}{47.750/54} = 4.349557 \stackrel{H_0}{\sim} f_{3, `r nrow(datos)-6`} \\
\end{split}
\end{equation}
```
Para el criterio de decisión calculamos el valor crítico a un nivel de significancia $\alpha = 0.05$ de una distribución $f_{0.05, 3, `r nrow(datos)-6`} = 4.349557$

Como $F_0$ > $f_{0.05, 3, `r nrow(datos)-6`}$, se rechaza la hipotesis nula, lo que quiere decir que al menos una de las variables regresoras asociadas a la Duración de la estadía, Rutina de culitivos y Número de enfermeras ($X_1, X_2, X_5$), es significativa en presencia del resto de variables y por lo tanto hace a este conjunto un conjunto significativo y no podemos descartarlo. subconjunto.


```{=tex}
\section{Pregunta 3}
\subsection{Prueba de hipótesis y prueba de hipótesis  matricial}
```
Se quiere estudiar si el efecto de la duración de estadía de los pacientes en el hospital es igual a la rutina de cultivos realizados en los pacientes sin síntoma de infección hospitalaria, por cada 100 pacientes. Además deseamos estudiar si el efecto promedio de camas en el hospital durante el periodo del estudio es igual al efecto del número promedio de pacientes en el hospital por día durante el periodo de estudio.

Para responder a la pregunta se plantea la siguiente prueba de hipótesis:

$$
\begin{cases}
\begin{aligned}
\text{H}_0&: \beta_1 = \beta_2; \ \beta_3  = \beta_4 \\
\text{H}_1&: \beta_1 \neq \beta_2 \ \ ó \ \ \beta_3 \neq \beta_4 \\
\end{aligned}
\end{cases}
$$
O equivalentemente,
$$
\begin{aligned}
\text{H}_0&: \beta_1 - \beta_2 = 0 \ ; \ \beta_3  - \beta_4 = 0 \\
\end{aligned}
$$

Además, se puede representar matricialmente de la siguiente forma: $$
\begin{cases}
\begin{aligned}
\text{H}_0&: \mathbf{L} \underline{\mathbf{\beta}} = \underline{\mathbf{0}} \\
\text{H}_1&: \mathbf{L} \underline{\mathbf{\beta}} \neq \underline{\mathbf{0}} \\
\end{aligned}
\end{cases}
$$

Con $\mathbf{L}$ dada por

$$
L = \begin{bmatrix}
  0 & 1 & -1 & 0 & 0 & 0\\
  0 & 0 & 0 & 1 & -1 & 0
\end{bmatrix}
$$

El modelo reducido es:

```{=tex}
\begin{equation}
\begin{split}
Y & = \beta_o  + \beta_1( X_{1}+X_{2}) + \beta_3 ( X_3+X_4) + \beta_5 X_5 + \varepsilon \\
& = \beta_o  + \beta_1 X_{1,2} + \beta_3 X_{3,4} + \beta_5 X_5
\end{split}
\end{equation}
```

Donde $X_{1,2} = X_1 + X_2$ y $X_{3,4} = X_3 + X_4$

\subsection{Estadístico de prueba}

Se tiene que el estadístico de prueba $F_0$ está dado por:

```{=tex}
\begin{equation}
F_0 = \frac{SSH/gl.ssh}{MSE(MF)} = \frac{(SSE(MR) - SSE(MF))/2}{MSE(MF)} \stackrel{H_0}{\sim} f_{2, `r nrow(datos)-6`}\\
\end{equation}
```
donde SSE(RM) corresponde al error estándar del modelo reducido, SSE(RM) corresponde al error estándar del modelo full, r corresponde al número de filas linealmente independientes en la matriz L que son 2, y el MSE(FM) a la media de errores estándar del modelo full.

Si $F_0 > f_{0.05, 2, 54}$ entonces se rechaza la hipotesis nula y al menos una de los dos supuestos que queremos probar no se cumple con una significancia del 95%.
\section{Pregunta 4}

\subsection{Supuestos del modelo}

\subsubsection{Normalidad de los residuales}

Para la validación de este supuesto, se planteará la siguiente prueba de
hipótesis shapiro-wilk, acompañada de un gráfico cuantil-cuantil: $$
\begin{cases}
\begin{aligned}
  \text{H}_0&: \varepsilon_i \sim \text{Normal}\\
  \text{H}_1&: \varepsilon_i \nsim \text{Normal}
\end{aligned}
\end{cases}
$$

```{r fig.cap = "Gráfico cuantil-cuantil y normalidad de residuales"}
myQQnorm(modelo, xlab = "Cuantiles teóricos",
         ylab = "Cuantiles muestrales", pch=20)
```

Al ser el P-valor aproximadamente igual a 0.5951 y teniendo en cuenta
que el nivel de significancia $\alpha = 0.05$, el P-valor es mucho mayor
y por lo tanto, no se rechazaría la hipótesis nula, es decir que los
datos distribuyen normal con media $\mu$ y varianza $\sigma^2$, sin
embargo la gráfica de comparación de cuantiles permite ver colas más
pesadas y patrones irregulares, al tener más poder el análisis gráfico,
se termina por rechazar el cumplimiento de este supuesto. Ahora se
validará si la varianza cumple con el supuesto de ser constante.

\subsubsection{Varianza constante}

```{r fig.cap = "Gráfico residuales estudentizados vs valores ajustados"}
res.stud <- round(rstandard(modelo), 4)
yhat <- round(modelo$fitted.values, 4)
plot(yhat, res.stud, xlab = "Valores Ajustados", 
     ylab = "Residuales Estudentizados", main = "Residuales Estudentizados vs Valores Ajustados", pch=20)
abline(h = 0, lty = 2, lwd = 2, col = 2)
```

En el gráfico de residuales estudentizados vs valores ajustados se puede
observar que no hay patrones en los que la varianza aumente, decrezca ni
un comportamiento que permita descartar una varianza constante, al no
haber evidencia suficiente en contra de este supuesto se acepta como
cierto. Además es posible observar media 0.

\subsection{Verificación de las observaciones}

```{r}
Cooks.D <- round(cooks.distance(modelo), 4)
hii.value <- round(hatvalues(modelo), 4)
Dffits <- round(dffits(modelo), 4)
base.diagnostico <- data.frame(res.stud, Cooks.D, hii.value, Dffits)
```

\subsubsection{Datos atípicos}

```{r fig.cap = "Identificación de datos atípicos"}
with(base.diagnostico,
     plot(res.stud, xlab="Observación", ylab = "Residuales",
          main = "Residuales estudentizados", pch = 20, ylim=c(-5, 5)))
abline(h = 3, col="red", lty = "dashed")
abline(h =- 3, col="red", lty = "dashed")
```

```{r include = F}
atipicos.criterio <- 3
base.diagnostico[base.diagnostico$res.stud > atipicos.criterio | base.diagnostico$res.stud < -atipicos.criterio, ]
```

Como se puede observar en la gráfica anterior, no hay datos atípicos en
el conjunto de datos pues ningún residual estudentizado sobrepasa el
criterio de $|r_{estud}| > 3$.

\subsubsection{Puntos de balanceo}

```{r fig.cap = "Identificación de puntos de balanceo"}
hii.criterio <- 2*(6/(nrow(datos)))
with(base.diagnostico,
     plot(hii.value, xlab="Observación", ylab = "Valor hii",
          main = "Gráfica de hii para las observaciones", pch = 20, ylim=c(-0.3, 0.3)))
abline(h = hii.criterio, col="red", lty = "dashed")
```

```{r include = F}
base.diagnostico[base.diagnostico$hii.value > hii.criterio, ]
```

Al observar la gráfica de observaciones vs valores $h_{ii}$, donde la
línea punteada roja representa el valor $h_{ii} = 2\frac{p}{n}$, se
puede apreciar que existen 5 datos del conjunto que son puntos de
balanceo según el criterio bajo el cual $h_{ii} > 2\frac{p}{n}$, los
cuales son los presentados en la tabla.

\subsubsection{Puntos  influenciales}

```{r fig.cap="Criterio distancias de Cook para puntos influenciales"}
criterio.cook <- 1
with(base.diagnostico,
     plot(Cooks.D, xlab="Observación", ylab = "Distancia de Cook",
          main = "Gráfica de distancias de Cook", pch = 20, ylim=c(-1.5, 1.5)))
abline(h = criterio.cook, col="red", lty = "dashed")
#base.diagnostico[base.diagnostico$Cooks.D > criterio.cook, ]
```

```{r fig.cap="Criterio Dffits para puntos influenciales"}
Dffits.criterio <- 2* (6/nrow(datos))^(1/2)
with(base.diagnostico,
     plot(Dffits, xlab="Observación", ylab = "Dffit",
          main = "Gráfica de observaciones vs Dffits", pch = 20, ylim=c(-1.5, 1.5)))
abline(h = Dffits.criterio, col="red", lty = "dashed")
abline(h = -Dffits.criterio, col="red", lty = "dashed")
base.diagnostico[base.diagnostico$Dffits > Dffits.criterio | base.diagnostico$Dffits < -Dffits.criterio, ]
```

Como se puede ver,las observaciones ... son puntos influenciales según
el criterio de Dffits, el cual dice que para cualquier punto cuyo
$|D_{ffit}| > 2\sqrt{\frac{p}{n}}$, es un punto influencial. Cabe
destacar también que con el criterio de distancias de Cook, en el cual
para cualquier punto cuya $D_{i} > 1$, es un punto influencial, ninguno
de los datos cumple con serlo.

\subsection{Conclusión}
